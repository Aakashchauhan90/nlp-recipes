{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstractive Summarization on CNN/DM Dataset using Transformers\n",
    "\n",
    "\n",
    "### Summary\n",
    "\n",
    "This notebook demonstrates how to fine tune Transformers for extractive text summarization. Utility functions and classes in the NLP Best Practices repo are used to facilitate data preprocessing, model training, model scoring, result postprocessing, and model evaluation.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Before You Start\n",
    "\n",
    "The running time shown in this notebook is on a Standard_NC24s_v3 Azure Ubuntu Virtual Machine with 4 NVIDIA Tesla V100 GPUs. \n",
    "> **Tip**: If you want to run through the notebook quickly, you can set the **`QUICK_RUN`** flag in the cell below to **`True`** to run the notebook on a small subset of the data and a smaller number of epochs. \n",
    "\n",
    "Using only 1 NVIDIA Tesla V100 GPUs, 16GB GPU memory configuration,\n",
    "- for data preprocessing, it takes around 1 minutes to preprocess the data for quick run. Otherwise it takes ~20 minutes to finish the data preprocessing. This time estimation assumes that the chosen transformer model is \"distilbert-base-uncased\" and the sentence selection method is \"greedy\", which is the default. The preprocessing time can be significantly longer if the sentence selection method is \"combination\", which can achieve better model performance.\n",
    "\n",
    "- for model fine tuning, it takes around 2 minutes for quick run. Otherwise, it takes around ~3 hours to finish. This estimation assumes the chosen encoder method is \"transformer\". The model fine tuning time can be shorter if other encoder method is chosen, which may result in worse model performance. \n",
    "\n",
    "### Additional Notes\n",
    "\n",
    "* **ROUGE Evalation**: To run rouge evaluation, please refer to the section of compute_rouge_perl in [summarization_evaluation.ipynb](./summarization_evaluation.ipynb) for setup.\n",
    "\n",
    "* **Distributed Training**:\n",
    "Please note that the jupyter notebook only allows to use pytorch [DataParallel](https://pytorch.org/docs/master/nn.html#dataparallel). Faster speed and larger batch size can be achieved with pytorch [DistributedDataParallel](https://pytorch.org/docs/master/notes/ddp.html)(DDP). Script [extractive_summarization_cnndm_distributed_train.py](./extractive_summarization_cnndm_distributed_train.py) shows an example of how to use DDP.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "## Set QUICK_RUN = True to run the notebook on a small subset of data and a smaller number of epochs.\n",
    "QUICK_RUN = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daden/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/daden/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/daden/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/daden/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/daden/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/daden/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/daden/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/daden/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/daden/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/daden/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/daden/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/daden/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from tempfile import TemporaryDirectory\n",
    "import torch\n",
    "\n",
    "nlp_path = os.path.abspath(\"../../\")\n",
    "if nlp_path not in sys.path:\n",
    "    sys.path.insert(0, nlp_path)\n",
    "\n",
    "from utils_nlp.dataset.cnndm import CNNDMBertSumProcessedData, CNNDMSummarizationDataset\n",
    "from utils_nlp.eval import compute_rouge_python, compute_rouge_perl\n",
    "from utils_nlp.models.transformers.abstractive_summarization_bartt5 import AbstractiveSummarizer, SummarizationProcessor\n",
    "\n",
    "from utils_nlp.models.transformers.datasets import SummarizationDataset\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "\n",
    "import pandas as pd\n",
    "import scrapbook as sb\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Configuration: choose the transformer model to be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several pretrained models have been made available by [Hugging Face](https://github.com/huggingface/transformers). For extractive summarization, the following pretrained models are supported. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame({\"model_name\": ExtractiveSummarizer.list_supported_models()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Transformer model being used\n",
    "MODEL_NAME = \"t5-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e18ad04d5d6c472c88c306c15e6f16c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=791656, style=ProgressStyle(description_widâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b49de228e3e4d619182ce0081b6d953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=1200, style=ProgressStyle(description_widthâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# notebook parameters\n",
    "# the cache data path during find tuning\n",
    "CACHE_DIR = TemporaryDirectory().name\n",
    "        \n",
    "processor = SummarizationProcessor(MODEL_NAME,cache_dir=CACHE_DIR ) #tokenizer, config.prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "The dataset we used for this notebook is CNN/DM dataset which contains the documents and accompanying questions from the news articles of CNN and Daily mail. The highlights in each article are used as summary. The dataset consits of ~289K training examples, ~11K valiation examples and ~11K test examples.   The code in following cell will download the CNN/DM dataset listed at https://github.com/harvardnlp/sent-summary/.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# the data path used to save the downloaded data file\n",
    "DATA_PATH = TemporaryDirectory().name\n",
    "# The number of lines at the head of data file used for preprocessing. -1 means all the lines.\n",
    "TOP_N = 1000\n",
    "if not QUICK_RUN:\n",
    "    TOP_N = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 489k/489k [00:07<00:00, 63.4kKB/s] \n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = CNNDMSummarizationDataset(top_n=TOP_N, local_cache_path=DATA_PATH, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "abs_sum_train = processor.preprocess(train_dataset)\n",
    "abs_sum_test = processor.preprocess(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# save and load preprocessed data\\nsave_path = os.path.join(DATA_PATH, \"processed\")\\ntorch.save(ext_sum_train, os.path.join(save_path, \"train_full.pt\"))\\ntorch.save(ext_sum_test, os.path.join(save_path, \"test_full.pt\"))\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# save and load preprocessed data\n",
    "save_path = os.path.join(DATA_PATH, \"processed\")\n",
    "torch.save(ext_sum_train, os.path.join(save_path, \"train_full.pt\"))\n",
    "torch.save(ext_sum_test, os.path.join(save_path, \"test_full.pt\"))\n",
    "\n",
    "\"\"\"\n",
    "# ext_sum_train = torch.load(os.path.join(save_path, \"train_full.pt\"))\n",
    "# ext_sum_test = torch.load(os.path.join(save_path, \"test_full.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(abs_sum_train))\n",
    "print(len(abs_sum_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['src', 'src_txt', 'tgt', 'tgt_txt', 'source_ids', 'source_mask', 'target_ids'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_sum_train[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'src': \"editor 's note : in our behind the scenes series , cnn correspondents share their experiences in covering news and analyze the stories behind the events . here , soledad o'brien takes users inside a jail where many of the inmates are mentally ill . an inmate housed on the `` forgotten floor , '' where many mentally ill inmates are housed in miami before trial . miami , florida -lrb- cnn -rrb- -- the ninth floor of the miami-dade pretrial detention facility is dubbed the `` forgotten floor . '' here , inmates with the most severe mental illnesses are incarcerated until they 're ready to appear in court . most often , they face drug charges or charges of assaulting an officer -- charges that judge steven leifman says are usually `` avoidable felonies . '' he says the arrests often result from confrontations with police . mentally ill people often wo n't do what they 're told when police arrive on the scene -- confrontation seems to exacerbate their illness and they become more paranoid , delusional , and less likely to follow directions , according to leifman . so , they end up on the ninth floor severely mentally disturbed , but not getting any real help because they 're in jail . we toured the jail with leifman . he is well known in miami as an advocate for justice and the mentally ill . even though we were not exactly welcomed with open arms by the guards , we were given permission to shoot videotape and tour the floor . go inside the ` forgotten floor ' '' at first , it 's hard to determine where the people are . the prisoners are wearing sleeveless robes . imagine cutting holes for arms and feet in a heavy wool sleeping bag -- that 's kind of what they look like . they 're designed to keep the mentally ill patients from injuring themselves . that 's also why they have no shoes , laces or mattresses . leifman says about one-third of all people in miami-dade county jails are mentally ill . so , he says , the sheer volume is overwhelming the system , and the result is what we see on the ninth floor . of course , it is a jail , so it 's not supposed to be warm and comforting , but the lights glare , the cells are tiny and it 's loud . we see two , sometimes three men -- sometimes in the robes , sometimes naked , lying or sitting in their cells . `` i am the son of the president . you need to get me out of here ! '' one man shouts at me . he is absolutely serious , convinced that help is on the way -- if only he could reach the white house . leifman tells me that these prisoner-patients will often circulate through the system , occasionally stabilizing in a mental hospital , only to return to jail to face their charges . it 's brutally unjust , in his mind , and he has become a strong advocate for changing things in miami . over a meal later , we talk about how things got this way for mental patients . leifman says 200 years ago people were considered `` lunatics '' and they were locked up in jails even if they had no charges against them . they were just considered unfit to be in society . over the years , he says , there was some public outcry , and the mentally ill were moved out of jails and into hospitals . but leifman says many of these mental hospitals were so horrible they were shut down . where did the patients go ? nowhere . the streets . they became , in many cases , the homeless , he says . they never got treatment . leifman says in 1955 there were more than half a million people in state mental hospitals , and today that number has been reduced 90 percent , and 40,000 to 50,000 people are in mental hospitals . the judge says he 's working to change this . starting in 2008 , many inmates who would otherwise have been brought to the `` forgotten floor '' will instead be sent to a new mental health facility -- the first step on a journey toward long-term treatment , not just punishment . leifman says it 's not the complete answer , but it 's a start . leifman says the best part is that it 's a win-win solution . the patients win , the families are relieved , and the state saves money by simply not cycling these prisoners through again and again . and , for leifman , justice is served . e-mail to a friend .\\n\",\n",
       " 'src_txt': \"editor 's note : in our behind the scenes series , cnn correspondents share their experiences in covering news and analyze the stories behind the events . here , soledad o'brien takes users inside a jail where many of the inmates are mentally ill . an inmate housed on the `` forgotten floor , '' where many mentally ill inmates are housed in miami before trial . miami , florida -lrb- cnn -rrb- -- the ninth floor of the miami-dade pretrial detention facility is dubbed the `` forgotten floor . '' here , inmates with the most severe mental illnesses are incarcerated until they 're ready to appear in court . most often , they face drug charges or charges of assaulting an officer -- charges that judge steven leifman says are usually `` avoidable felonies . '' he says the arrests often result from confrontations with police . mentally ill people often wo n't do what they 're told when police arrive on the scene -- confrontation seems to exacerbate their illness and they become more paranoid , delusional , and less likely to follow directions , according to leifman . so , they end up on the ninth floor severely mentally disturbed , but not getting any real help because they 're in jail . we toured the jail with leifman . he is well known in miami as an advocate for justice and the mentally ill . even though we were not exactly welcomed with open arms by the guards , we were given permission to shoot videotape and tour the floor . go inside the ` forgotten floor ' '' at first , it 's hard to determine where the people are . the prisoners are wearing sleeveless robes . imagine cutting holes for arms and feet in a heavy wool sleeping bag -- that 's kind of what they look like . they 're designed to keep the mentally ill patients from injuring themselves . that 's also why they have no shoes , laces or mattresses . leifman says about one-third of all people in miami-dade county jails are mentally ill . so , he says , the sheer volume is overwhelming the system , and the result is what we see on the ninth floor . of course , it is a jail , so it 's not supposed to be warm and comforting , but the lights glare , the cells are tiny and it 's loud . we see two , sometimes three men -- sometimes in the robes , sometimes naked , lying or sitting in their cells . `` i am the son of the president . you need to get me out of here ! '' one man shouts at me . he is absolutely serious , convinced that help is on the way -- if only he could reach the white house . leifman tells me that these prisoner-patients will often circulate through the system , occasionally stabilizing in a mental hospital , only to return to jail to face their charges . it 's brutally unjust , in his mind , and he has become a strong advocate for changing things in miami . over a meal later , we talk about how things got this way for mental patients . leifman says 200 years ago people were considered `` lunatics '' and they were locked up in jails even if they had no charges against them . they were just considered unfit to be in society . over the years , he says , there was some public outcry , and the mentally ill were moved out of jails and into hospitals . but leifman says many of these mental hospitals were so horrible they were shut down . where did the patients go ? nowhere . the streets . they became , in many cases , the homeless , he says . they never got treatment . leifman says in 1955 there were more than half a million people in state mental hospitals , and today that number has been reduced 90 percent , and 40,000 to 50,000 people are in mental hospitals . the judge says he 's working to change this . starting in 2008 , many inmates who would otherwise have been brought to the `` forgotten floor '' will instead be sent to a new mental health facility -- the first step on a journey toward long-term treatment , not just punishment . leifman says it 's not the complete answer , but it 's a start . leifman says the best part is that it 's a win-win solution . the patients win , the families are relieved , and the state saves money by simply not cycling these prisoners through again and again . and , for leifman , justice is served . e-mail to a friend .\\n\",\n",
       " 'tgt': \"<t> mentally ill inmates in miami are housed on the `` forgotten floor '' </t> <t> judge steven leifman says most are there as a result of `` avoidable felonies '' </t> <t> while cnn tours facility , patient shouts : `` i am the son of the president '' </t> <t> leifman says the system is unjust and he 's fighting for change . </t>\\n\",\n",
       " 'tgt_txt': \"<t> mentally ill inmates in miami are housed on the `` forgotten floor '' </t> <t> judge steven leifman says most are there as a result of `` avoidable felonies '' </t> <t> while cnn tours facility , patient shouts : `` i am the son of the president '' </t> <t> leifman says the system is unjust and he 's fighting for change . </t>\\n\",\n",
       " 'source_ids': tensor([21603,    10,  6005,  ...,  2027,  2957,   307]),\n",
       " 'source_mask': tensor([1, 1, 1,  ..., 1, 1, 1]),\n",
       " 'target_ids': tensor([    3,     2,    17,  3155, 19367,     3,  1092,    16, 11171,    16,\n",
       "          1337,  3690,    33,   629,    26,    30,     8,     3,     2, 11821,\n",
       "          1501,     3,    31,    31,     3,     2,    87,    17,  3155,     3,\n",
       "             2,    17,  3155,  5191,     3,   849,  1926,    90,    99,   348,\n",
       "           845,   167,    33,   132,    38,     3,     9,   741,    13,     3,\n",
       "             2,  1792,   179,  3110,   106,   725])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_sum_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training\n",
    "To start model training, we need to create a instance of ExtractiveSummarizer.\n",
    "#### Choose the transformer model.\n",
    "Currently ExtractiveSummarizer support two models:\n",
    "- distilbert-base-uncase, \n",
    "- bert-base-uncase\n",
    "\n",
    "Potentionally, roberta-based model and xlnet can be supported but needs to be tested.\n",
    "#### Choose the encoder algorithm.\n",
    "There are four options:\n",
    "- baseline: it used a smaller transformer model to replace the bert model and with transformer summarization layer\n",
    "- classifier: it uses pretrained BERT and fine-tune BERT with **simple logistic classification** summarization layer\n",
    "- transformer: it uses pretrained BERT and fine-tune BERT with **transformer** summarization layer\n",
    "- RNN: it uses pretrained BERT and fine-tune BERT with **LSTM** summarization layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5 # batch size, unit is the number of samples\n",
    "MAX_POS_LENGTH = 512\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# GPU used for training\n",
    "NUM_GPUS = torch.cuda.device_count()\n",
    "\n",
    "\n",
    "# Learning rate\n",
    "LEARNING_RATE=2e-3\n",
    "\n",
    "# How often the statistics reports show up in training, unit is step.\n",
    "REPORT_EVERY=100\n",
    "\n",
    "# total number of steps for training\n",
    "MAX_STEPS=1e2\n",
    "# number of steps for warm up\n",
    "WARMUP_STEPS=5e2\n",
    "    \n",
    "if not QUICK_RUN:\n",
    "    MAX_STEPS=5e4\n",
    "    WARMUP_STEPS=5e3\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summarizer = AbstractiveSummarizer(processor, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nsummarizer.fit(\\n            ext_sum_train,\\n            num_gpus=NUM_GPUS,\\n            batch_size=BATCH_SIZE,\\n            gradient_accumulation_steps=2,\\n            max_steps=MAX_STEPS,\\n            learning_rate=LEARNING_RATE,\\n            warmup_steps=WARMUP_STEPS,\\n            verbose=True,\\n            report_every=REPORT_EVERY,\\n            clip_grad_norm=False,\\n            use_preprocessed_data=USE_PREPROCSSED_DATA\\n        )\\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "summarizer.fit(\n",
    "            ext_sum_train,\n",
    "            num_gpus=NUM_GPUS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            gradient_accumulation_steps=2,\n",
    "            max_steps=MAX_STEPS,\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            warmup_steps=WARMUP_STEPS,\n",
    "            verbose=True,\n",
    "            report_every=REPORT_EVERY,\n",
    "            clip_grad_norm=False,\n",
    "            use_preprocessed_data=USE_PREPROCSSED_DATA\n",
    "        )\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsummarizer.save_model(\\n    os.path.join(\\n        CACHE_DIR,\\n        \"extsum_modelname_{0}_usepreprocess{1}_steps_{2}.pt\".format(\\n            MODEL_NAME, USE_PREPROCSSED_DATA, MAX_STEPS\\n        ),\\n    )\\n)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "summarizer.save_model(\n",
    "    os.path.join(\n",
    "        CACHE_DIR,\n",
    "        \"extsum_modelname_{0}_usepreprocess{1}_steps_{2}.pt\".format(\n",
    "            MODEL_NAME, USE_PREPROCSSED_DATA, MAX_STEPS\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport torch\\nmodel_path = os.path.join(\\n        CACHE_DIR,\\n        \"extsum_modelname_{0}_usepreprocess{1}_steps_{2}.pt\".format(\\n            MODEL_NAME, USE_PREPROCSSED_DATA, MAX_STEPS\\n        ))\\nsummarizer = ExtractiveSummarizer(processor, MODEL_NAME, ENCODER, MAX_POS_LENGTH, CACHE_DIR)\\nsummarizer.model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for loading a previous saved model\n",
    "\"\"\"\n",
    "import torch\n",
    "model_path = os.path.join(\n",
    "        CACHE_DIR,\n",
    "        \"extsum_modelname_{0}_usepreprocess{1}_steps_{2}.pt\".format(\n",
    "            MODEL_NAME, USE_PREPROCSSED_DATA, MAX_STEPS\n",
    "        ))\n",
    "summarizer = ExtractiveSummarizer(processor, MODEL_NAME, ENCODER, MAX_POS_LENGTH, CACHE_DIR)\n",
    "summarizer.model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "[ROUGE](https://en.wikipedia.org/wiki/ROUGE_(metric)), or Recall-Oriented Understudy for Gisting Evaluation has been commonly used for evaluating text summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['src', 'src_txt', 'tgt', 'tgt_txt', 'source_ids', 'source_mask', 'target_ids'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_sum_test[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = []\n",
    "target = []\n",
    "for i in abs_sum_test:\n",
    "    source.append(i[\"src_txt\"]) \n",
    "    target.append(i['tgt']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<t> marseille prosecutor says `` so far no videos were used in the crash investigation '' despite media reports . </t> <t> journalists at bild and paris match are `` very confident '' the video clip is real , an editor says . </t> <t> andreas lubitz had informed his lufthansa training school of an episode of severe depression , airline says . </t>\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating summary:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset length is 20\n",
      "tensor([[    0,   183,    29,   222,    63,  1038,    31,     7,  2041,   934,\n",
      "         10173,     7,     8,   169,    13,   538,    18,     7,   152,  4985,\n",
      "            15,    26,  9357,    38,     3,     9,  4930,    23,  3268,  3613,\n",
      "           640,     8,  7895,     3,     5,    44,   709,  1640,   940,   151,\n",
      "           130, 13763,   300,     8,   296,    16,  1412,     3,     5,    44,\n",
      "           709,  3547,   591,  3539,   151, 13448,    33,  5899,    12,    43,\n",
      "           118, 14014,     8,  7142,     3,     5,     1],\n",
      "        [    0,   183,    29,   222,    63,  1038, 10375,  2041,  1132,    13,\n",
      "          1687, 10736,  4388,     3,     5,  1687, 16513,    95,  2899,  1454,\n",
      "            30,  1767,   215,     6,  3323,   250,    13,     3, 16864,   343,\n",
      "           152,     3,     5,  1440,   338,  1687, 10736,    12,  8000,  5447,\n",
      "            11,     3, 14389,    33,    20,   565,    23,  3745,  1452,     3,\n",
      "             5,     1,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]], device='cuda:1')\n",
      "tensor([[    0,     3,  4515,     3,    89,  6254,  3977,    13,     3, 12575,\n",
      "         11823,    16,     3,     9, 28577,    23,  6145,  2856,    44,     8,\n",
      "          1246,    13,   627,     3,     5,   126,   585,  1267,    24,   255,\n",
      "            11,   160,  2749,  4806,  1077,   410,    59,  7905,    12, 10556,\n",
      "         18315,     3,     5,     8,  2883,  5128,    13,  1687,    21,     3,\n",
      "          4515,    11,  3157, 10779,  2367, 19363,     3,     5,     1,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [    0,     3,     9,   146,  1050,  1236,    65, 10246,    12,  7442,\n",
      "             3,     9,   150,    32,     7,    15,   263,    13, 13888,    45,\n",
      "             3,     9,  2195,  1084,     3,     9,  1236,  7021,     3,     6,\n",
      "          3819,  4298,   243,     3,   189,  3589,  1135,     3,     5,     8,\n",
      "             3, 13003,  1045,   496,   410,     3,    29,    31,    17,  2862,\n",
      "             8,  1236,     3,     6,     3, 17994,  2822,  4570,  3786,     3,\n",
      "             5,    16,     3,     9,  1506,  1576,     3,     6,    34,   243,\n",
      "             8,  1236,    47,   150,  1200,    30,  4730,    11,    56,   522,\n",
      "          1236,  3498,  1132,     3,     5,     1]], device='cuda:2')\n",
      "tensor([[    0,     8,  5109,     5,     3,  5840,    49,    17,     3,   107,\n",
      "             5,     3, 14800,  1171,     3,     6,     3, 15534,  1161,    29,\n",
      "            23,     9,     3,  1625, 22611,     7,    17,    11,  7174,    13,\n",
      "             8,  4390,  8409,     3,     2,  1781,    13,   579,     3,     6,\n",
      "             3,    31,    31,  3977,     3,   189,  3589,  1135,     3,     6,\n",
      "          1315,    12,   112,   384,     3,     5,     3,    88,    47,     3,\n",
      "          4060,   203,   625,     3,     5,     3, 14800,  1171,     3,     6,\n",
      "            92,     8,  7174,    13,  6884, 26411, 13950, 28854,     3,     6,\n",
      "           141,   118, 12223,    28,     3,    15,     7, 10775,   545,   138,\n",
      "          1874,    16, 14663,  2038,     3,     5,     1],\n",
      "        [    0,     8,  1782,    47,  1560,    57,     3,     9,   443,     6,\n",
      "          8743,  4792,    28,     3,     9,     3,  1483,   935,    11,     3,\n",
      "         14656,    16,     3,     9,  1057,     3,     5,   255,  3342,  4102,\n",
      "          3737,    12,     3,     9,  4676,  3797,     6,  9404,    18, 28161,\n",
      "            11,     3,    15,    51,  4268,   920,     3,     5,     8,  1782,\n",
      "            47,   435,    57,     3,     9, 10416,   113,   808,   160,    12,\n",
      "             3,     9, 14065,    21,   199,     3,     5,   255,  8151,     3,\n",
      "             9,  1028,  5133,   920,  9657,     6,  4553,  5157,    11,     3,\n",
      "             9,  9634,    26,    18,    77, 23353, 25864,     3,     5,     1,\n",
      "             0,     0,     0,     0,     0,     0,     0]], device='cuda:3')\n",
      "tensor([[    0,  8113, 15955,     3,     6,  2515,   663,     3,    18,     3,\n",
      "            75,    29,    29,     3,    18,     8, 20609, 23489,   127,  1374,\n",
      "            46,  4962,   139,     8,  8420,    13, 13692,  3108,     7,  3777,\n",
      "         11923,  1828,    16, 15777,    62,    26,  1496,  1135,    24,     3,\n",
      "            88,    47,    59,  2718,    13,   136,   671, 13420,    45,    30,\n",
      "          1476,     8,  6112,     3,     5,  8113, 15955, 23489,   127,     3,\n",
      "           115,  4920,     3,  5840,    77,  1219,     3,    75,    29,    29,\n",
      "            24,     3,     2,    78,   623,   150,  3075,   130,   261,    16,\n",
      "             8,  8420,  4962,     3,     5,     3,    31,    31,     3,  5840,\n",
      "            77,     3,    31,     7,  2622,  1130,  3213,    57,   192, 13254,\n",
      "             3,     6, 13692,  1444,     3,  9401,    11, 20609,   260,   159,\n",
      "          1588,     3,     6,    13,     1],\n",
      "        [    0,     8,  4727,  4991,  1938,    47,  7027,    28,     3,     9,\n",
      "          7252,    44,     8,  4244,  5398,     3,     6,    16,     8,  3134,\n",
      "           760,  6347,     3,     6,   213,     8,  1614,    19,     3,   390,\n",
      "             3,     5,     8,  7692,   222,    77,  7137,  3814,     8,     3,\n",
      "           447,    75,    31,     7, 16072,     3, 11956, 18692,    16,     3,\n",
      "          7066,    76,  1208,     3,     5,    38,   724,    13,     8,  1614,\n",
      "             3,     6,  7692,   222,    77,  7137,   164,    36,  1426,    12,\n",
      "          3485,    18,  7993,     7,    38,   168,     3,     5,     1,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating summary:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:17<00:34, 17.37s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,   874, 10211,     7,   113,   130, 18259,    21,   386,  1274,\n",
      "            44,    46,     3,    32,    51,     9,  1024,  2833,    43,   118,\n",
      "          1883,     3,     5,    80,    13,     8,   874,   141,     3,     9,\n",
      "           842,    18,  3897,   962,    30,     3,     7,  6010,  1135,    11,\n",
      "            65,   118, 12445,    26,    68,    65,     3,    29,    31,    17,\n",
      "           646,     8,   616,     3,     5,    79,   130,  6666,    12,     3,\n",
      "            15,  4243,     9,    16,   108, 16841,    90,   782,    16, 10556,\n",
      "             3,     5,     1,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [    0,    11,    60,   210,   129,    17,    63,     6, 10635,     6,\n",
      "            47,   435,  3654,    16,   112, 10381, 11831,    15,     7,   234,\n",
      "             3,     5,     8,  4301,   106,    49,    31,     7, 17413,  4193,\n",
      "            19,   132,    47,   150, 16704,   577,  1381,    16,     8,  1687,\n",
      "            13,   129,    17,    63,     3,     5,   129,    17,    63,     3,\n",
      "             6, 10017,   106,    13,  1043,     3,    17,    63,   509,   106,\n",
      "             3,   354,     5,  2576,    83,   129,    17,    63,     3,     6,\n",
      "            47,   435,  3654,  1084,     3,     9,  2582,    16,   112,   234,\n",
      "             3,     5,     1]], device='cuda:3')\n",
      "tensor([[    0,     3,    18,    40,    52,   115,    18,     3,    88,     3,\n",
      "            31,     7,     3,     9,  1692,  6591,  1900,  8498, 11474,     3,\n",
      "             5,   255,     3,    31,     7,     3,     9,   306,   496, 22857,\n",
      "            28,   323, 12398,     3,     5,    44,   166, 15963,     3,   929,\n",
      "            63,  2288,  2260,    11,     3,  7999,    15,     3,   935, 11272,\n",
      "           107,   228,     3,    29,    31,    17,    36,    72,   315,     3,\n",
      "             5,    68,    66,    24,  2130,     3,   189,  3589,  1135,   116,\n",
      "             3,   929,    63,  1380,     3,  7999,    15,    12,    36,   112,\n",
      "         15207,   833,     3,     5,     1,     0,     0,     0,     0,     0],\n",
      "        [    0,  2278,   400,     3,  6425,  2434,     3,  2172,  2753,     3,\n",
      "            32,   115,   265,     9,    12,     8,   576,    18, 24650,    13,\n",
      "             8,   103,    32,  2726, 13692,  3108,     7,  3777,     3,     5,\n",
      "             3,    31,    31,  4065,   112,     3,    23,  2002,  1154,     3,\n",
      "             6,  1207,  4365,     3,    32,   115,   265,     9,    19,    21,\n",
      "             8,  3147,   770,  3668,     7,    13,     8, 18279,  2315,     6,\n",
      "            31,    31,   255,  2832,    16,     3,     9, 13301,  1670,  1694,\n",
      "         10556,  2664,     3,     5,   186,  2622,  1694,    30,   160, 13301,\n",
      "           543,     3,   115, 19054,     8,  1798,  6978,     3,     5,     1]],\n",
      "       device='cuda:1')\n",
      "tensor([[    0,  2288,  1483, 11374,     3, 27578,    26,     3,  7061,    99,\n",
      "            19,     8,     3,    23,    52,     9, 15710,  2959,  6323,     3,\n",
      "             5,     3,    88,    65,   118,     3, 27341,     3,  2304,   651,\n",
      "            31,     7,  6401,   381,    16,     3,     7, 17348,  6414, 20974,\n",
      "             3,     5,     3,  7061,    99,    19, 10630,     6,    68,   112,\n",
      "          2314, 25705,   845,     3,    88,    47,  2170,    16,  8754,     3,\n",
      "             5,     3,    88,    47, 18277,    57,     8, 13126,     7,   147,\n",
      "           112,     3, 12554,  1075,    16, 14498,     3,     9, 18533,  1470,\n",
      "             3,     5,     1,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    0,    21,     8,   166,    97,    16,  2641,   203,     3,     6,\n",
      "             3,     9,     3,    17,   208,  9503,  3666,    12,   692,   125,\n",
      "             3,    88,   405,   200,     3,     5,  4233,  2366,  1219,    12,\n",
      "             3,     2,   369,    30,   323,     3,    55,     3,    31,    31,\n",
      "            30,     8,     3,     9,  2246,    40,   209,  4182,    13,     3,\n",
      "             2,     8,   594,    19,   269,     3,    31,    31, 15110,    59,\n",
      "          2290,     3,    26,    60,   210,   124,    63,    68,   430,  3324,\n",
      "           522,    16,  1567,    13,     8, 13339,     3,     5,  1446,     3,\n",
      "             6,   132,    47,     3, 17396, 21696,    49,     3,     6,   113,\n",
      "          6523,     8,     3,    17,   208,   467,   504,    21,  3097,   203,\n",
      "           274,     3, 19115,   323,    16,  4101,     3,     5,     1]],\n",
      "       device='cuda:0')\n",
      "tensor([[    0,     3, 15534,  1161,    29,    23,     9,    19,     3,     9,\n",
      "          4109,  4883,  8044,    12,     8,  2982,     3,     5,     3, 15534,\n",
      "          1161,    29,    23,     9,    19,  1710,    72,   145,     3,     9,\n",
      "          1025,    13,   165,  6205,    11,  2111,   192,    18, 14965,     7,\n",
      "            13,   165,  6533,    11, 11446,     3,     5,     8, 19611,    19,\n",
      "            16,   165,  4509,   215,     3,     5,     1,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [    0, 24140,    31,     7, 16269,  5457, 12334,    13,     3,     9,\n",
      "          4761,  4333,   973,    16,   165,   234,   538,    13,     3,  6604,\n",
      "          3247,     9,     7,   764,   227,     8,   349,   243,    16, 29976,\n",
      "            76,  1208,    34,   133,  4888,   726,    21,    81,     3, 23221,\n",
      "          2765,   168,   756,     8,  2822,  2559, 11458,     3,     5,     8,\n",
      "           349,    19,  7821,    38,     3,     9, 12815,   210, 16764,    21,\n",
      "         16739,   452,  3474,    30,  1312,    18,   115, 12499,  1827,   807,\n",
      "            24, 14514, 11252,     7,    11, 10215,     7,     3,     5,  1798,\n",
      "          3519,  1496,    32,    17,     9,     3,  9527,     5,     3,  2998,\n",
      "             3, 19589,  6987,    63,   243, 24140,    31,     7,  2874,     3,\n",
      "             2,    21,    15, 21509,   213,     8, 20237,   152,  1088,    56,\n",
      "           174,    12,   888,     3,     1]], device='cuda:2')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating summary:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:33<00:17, 17.03s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     3, 24063,  3977,    16,     3,  5326, 18247,  2038,   227,\n",
      "             3,     9, 12061,    63,   443,  8420,     3,     5,     8,  1576,\n",
      "            13,     3,     2,  4223,  2936,   489,     3,    31,    31,    30,\n",
      "          9030,  1135,   704,  2675,     8,  1004,    12,  1423,  1636,    11,\n",
      "          3673, 20214,    15,   541,  1636,     8,   388,    24,    78,   186,\n",
      "            43,     3, 24266,    38,    80,    13,     8,  1245,     7,    17,\n",
      "          3413,    16,     3,   107, 30322,     3,     5,     1]],\n",
      "       device='cuda:3')\n",
      "tensor([[    0,     3, 20068,    15,   158,  3772,  3814,     3,     9,  4761,\n",
      "          4333,   973,   336,   471,    24,  9540,     8,  1365,    12,  9192,\n",
      "           257,   581, 16998,     7,    11,   110, 12032,     7,     3,     5,\n",
      "           158,  3772,    10,     3,    31,    23, 27539,   120,     3, 20964,\n",
      "            48,   773,    13,   223,  8058,     3,     5,     3,    31,    31,\n",
      "         12137,    19,   150,   194,     3,     9, 20237,   152,    54,   129,\n",
      "           190,     8,     3, 11577,  2329,   406,   177,  1063,  4733,     3,\n",
      "            40,   122,   115,    17,  2166,     6,    31,    31,     3,    88,\n",
      "           845,     3,     5,     1]], device='cuda:0')\n",
      "tensor([[    0,   361,  7446,    23,  4844,    33,   271, 15240,    12,    36,\n",
      "            30,  4879,    21,  4923,  8347,     7,    11,     3,  6347,    40,\n",
      "          9361,    38, 10468,  5536,   164,     7,  1639, 15319,     8,     3,\n",
      "             9, 10488,  3368,  2982,     3,     7,  6010,  1135,     3,     5,\n",
      "           131,     3,     9,   360,   477,   977,     3,     6,   164,     7,\n",
      "          1639,  6886,  1355,     3,    17,    63,  9553,   106,  2637,  2049,\n",
      "            12,   165, 14399,  4261,     3,  7656, 13551,     3,     5,    34,\n",
      "            65,   437,  1513,     3,     9,   418,    13,  7222,    38,    34,\n",
      "            65,  5955,  4653,    16,     8,     3,  5379,  3286,  5431,     3,\n",
      "             5,    34,     3,    31,     7,   230, 12910,    38,     3,     9,\n",
      "         10468,  5536,     3,     6,  1315,    12,     8,     3, 18118,    23,\n",
      "          1572,   630,  1157,  1969,     1]], device='cuda:1')\n",
      "tensor([[    0,  3701,    89,    32,    40,   157,     3,     6, 24556,    23,\n",
      "             9,     3,    18,     8,   511,     3,  5058,    13,     8,     3,\n",
      "          9492,  4411,  3980,  1077,   228,     3,    29,    31,    17,   857,\n",
      "           125,     3,    88,    47,  2492,     3,     5,  3986,    13,  2286,\n",
      "            45,  1322,   132,    47,     3,     9,   422,  3432,  4676,     3,\n",
      "             5,    44,   166,    34,  2299, 13876,     3,     5,    34,    47,\n",
      "            16,  1282,  2346,     3,     6,  6437,    12,    80,   596,     3,\n",
      "             5,     8,  4627,    13,     8, 11668,    18,  6259,   307,  6295,\n",
      "          4383,   816,    34,    47,     3,     9, 18082,    24,   141, 21146,\n",
      "            15,    26,     3,     5,     3,  5828,     3,     6,    38,    79,\n",
      "           530,  4645,     3,     6,    79,  1509,   132,    47,     3,     9,\n",
      "           388,    30,    34,     3,     1]], device='cuda:2')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating summary: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:48<00:00, 16.36s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 22s, sys: 23.7 s, total: 1min 46s\n",
      "Wall time: 50.1 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "prediction = summarizer.predict(abs_sum_test[0:20], num_gpus=NUM_GPUS, batch_size=8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[    0,  8113, 15955,     3,     6,  2515,   663,     3,    18,     3,\n",
    "            75,    29,    29,     3,    18,     8, 20609, 23489,   127,  1374,\n",
    "            46,  4962,   139,     8,  8420,    13, 13692,  3108,     7,  3777,\n",
    "         11923,  1828,    16, 15777,    62,    26,  1496,  1135,    24,     3,\n",
    "            88,    47,    59,  2718,    13,   136,   671, 13420,    45,    30,\n",
    "          1476,     8,  6112,     3,     5,  8113, 15955, 23489,   127,     3,\n",
    "           115,  4920,     3,  5840,    77,  1219,     3,    75,    29,    29,\n",
    "            24,     3,     2,    78,   623,   150,  3075,   130,   261,    16,\n",
    "             8,  8420,  4962,     3,     5,     3,    31,    31,     3,  5840,\n",
    "            77,     3,    31,     7,  2622,  1130,  3213,    57,   192, 13254,\n",
    "             3,     6, 13692,  1444,     3,  9401,    11, 20609,   260,   159,\n",
    "          1588,     3,     6,    13,     1],\n",
    "        [    0,     8,  4727,  4991,  1938,    47,  7027,    28,     3,     9,\n",
    "          7252,    44,     8,  4244,  5398,     3,     6,    16,     8,  3134,\n",
    "           760,  6347,     3,     6,   213,     8,  1614,    19,     3,   390,\n",
    "             3,     5,     8,  7692,   222,    77,  7137,  3814,     8,     3,\n",
    "           447,    75,    31,     7, 16072,     3, 11956, 18692,    16,     3,\n",
    "          7066,    76,  1208,     3,     5,    38,   724,    13,     8,  1614,\n",
    "             3,     6,  7692,   222,    77,  7137,   164,    36,  1426,    12,\n",
    "          3485,    18,  7993,     7,    38,   168,     3,     5,     1,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0]], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    0,  8113, 15955,     3,     6,  2515,   663,     3,    18,     3,\n",
      "           75,    29,    29,     3,    18,     8, 20609, 23489,   127,  1374,\n",
      "           46,  4962,   139,     8,  8420,    13, 13692,  3108,     7,  3777,\n",
      "        11923,  1828,    16, 15777,    62,    26,  1496,  1135,    24,     3,\n",
      "           88,    47,    59,  2718,    13,   136,   671, 13420,    45,    30,\n",
      "         1476,     8,  6112,     3,     5,  8113, 15955, 23489,   127,     3,\n",
      "          115,  4920,     3,  5840,    77,  1219,     3,    75,    29,    29,\n",
      "           24,     3,     2,    78,   623,   150,  3075,   130,   261,    16,\n",
      "            8,  8420,  4962,     3,     5,     3,    31,    31,     3,  5840,\n",
      "           77,     3,    31,     7,  2622,  1130,  3213,    57,   192, 13254,\n",
      "            3,     6, 13692,  1444,     3,  9401,    11, 20609,   260,   159,\n",
      "         1588,     3,     6,    13,     1], device='cuda:0')\n",
      "tensor([    0,     8,  4727,  4991,  1938,    47,  7027,    28,     3,     9,\n",
      "         7252,    44,     8,  4244,  5398,     3,     6,    16,     8,  3134,\n",
      "          760,  6347,     3,     6,   213,     8,  1614,    19,     3,   390,\n",
      "            3,     5,     8,  7692,   222,    77,  7137,  3814,     8,     3,\n",
      "          447,    75,    31,     7, 16072,     3, 11956, 18692,    16,     3,\n",
      "         7066,    76,  1208,     3,     5,    38,   724,    13,     8,  1614,\n",
      "            3,     6,  7692,   222,    77,  7137,   164,    36,  1426,    12,\n",
      "         3485,    18,  7993,     7,    38,   168,     3,     5,     1,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<map object at 0x7f0bd4c62ac8>'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"marseille , france - cnn - the french prosecutor leading an investigation into the crash of germanwings flight 9525 insisted wednesday that he was not aware of any video footage from on board the plane . marseille prosecutor brice robin told cnn that  so far no videos were used in the crash investigation . '' robin 's comments follow claims by two magazines , german daily bild and french paris match , of\",\n",
       " \"the formal accession was marked with a ceremony at the hague , in the netherlands , where the court is based . the palestinians signed the icc's founding rome statute in january . as members of the court , palestinians may be subject to counter-charges as well .\",\n",
       " \"amnesty international's annual report catalogs the use of state-sanctioned killing as a punitive measure across the globe . at least 607 people were executed around the world in 2014 . at least 2,466 people globally are confirmed to have been handed the sentence .\",\n",
       " 'amnesty international releases annual review of death penalty worldwide . death sentences up 500% on previous year, mostly because of pakistan . countries using death penalty to tackle crime and terrorism are deceiving themselves .',\n",
       " 'anne frank died of typhus in a nazi concentration camp at the age of 15 . new research shows that she and her older sister probably did not survive to march 1945 . the exact dates of death for anne and margot remain unclear .',\n",
       " \"a duke student has admitted to hanging a noose made of rope from a tree near a student union , university officials said thursday . the prestigious private school did n't identify the student , citing federal privacy laws . in a news release , it said the student was no longer on campus and will face student conduct review .\",\n",
       " \"the rev. robert h. schuller , california televangelist and founder of the television ministry  hour of power , '' died thursday , according to his family . he was 88 years old . schuller , also the founder of crystal cathedral megachurch , had been diagnosed with esophageal cancer in august 2013 .\",\n",
       " 'the dog was hit by a car, apparently killed with a hammer and buried in a field . she staggered to a nearby farm, dirt-covered and emaciated . the dog was found by a worker who took her to a vet for help . she suffered a dislocated jaw, leg injuries and a caved-in sinus cavity .',\n",
       " \"mohammad javad zarif is the iranian foreign minister . he has been john kerry's opposite number in securing nuclear breakthrough . zarif is 54, but his official biography says he was born in 1960 . he was investigated by the feds over his alleged role in controlling a charitable organization .\",\n",
       " \"for the first time in eight years , a tv legend returned to doing what he does best . contestants told to  come on down ! '' on the april 1 edition of  the price is right '' encountered not host drew carey but another familiar face in charge of the proceedings . instead , there was bob barker , who hosted the tv game show for 35 years before stepping down in 2007 .\",\n",
       " \"-lrb- he 's a blue chip college basketball recruit . she 's a high school freshman with down syndrome . at first glance trey moses and ellie meredith could n't be more different . but all that changed thursday when trey asked ellie to be his prom date .\",\n",
       " \"michele bachmann compared president obama to the co-pilot of the doomed germanwings flight . ''with his iran deal , barack obama is for the 300 million souls of the united states,'' she wrote in a facebook comment posted march 31 . many comments posted on her facebook page blasted the former representative .\",\n",
       " 'california is a breadbasket to the nation . california is growing more than a third of its vegetables and nearly two-thirds of its fruits and nuts . the drought is in its fourth year .',\n",
       " \"walmart's staunch criticism of a religious freedom law in its home state of arkansas came after the company said in february it would boost pay for about 500,000 workers well above the federal minimum wage . the company is emerging as a bellwether for shifting public opinion on hot-button political issues that divide conservatives and liberals . former minnesota gov. tim pawlenty said walmart's actions  foreshadow where the republican party will need to move \",\n",
       " \"five americans who were monitored for three weeks at an omaha hospital have been released . one of the five had a heart-related issue on saturday and has been discharged but has n't left the area . they were exposed to ebola in sierra leone in march .\",\n",
       " \"andrew getty, 47, was found dead in his los angeles home . the coroner's preliminary assessment is there was no foul play involved in the death of getty . getty , grandson of oil tycoon j. paul getty , was found dead near a bathroom in his home .\",\n",
       " \"mike pence signed a religious freedom law last week that opens the door to discrimination against gays and lesbians . pence: 'i foolishly hoped this kind of backlash . ''there is no way a republican can get through the pending primary without denouncing lgbt rights,'' he says .\",\n",
       " \"filipinos are being warned to be on guard for flash floods and landslides as tropical storm maysak approached the asian island nation saturday . just a few days ago , maysak gained super typhoon status thanks to its sustained 150 mph winds . it has since lost a lot of steam as it has spun west in the pacific ocean . it 's now classified as a tropical storm , according to the philippine national weather\",\n",
       " \"norfolk , virginia - the second mate of the houston express probably could n't believe what he was seeing . hundreds of miles from land there was a small boat nearby . at first it looked abandoned . it was in bad shape , listing to one side . the crew of the 1,000-foot long container ship thought it was a yacht that had wrecked . incredibly , as they got closer , they saw there was a man on it \",\n",
       " \"walker died in november 2013 after a fiery car crash . the release of  furious 7 '' on friday offers fans the opportunity to remember -- and possibly grieve again -- the man that so many have praised as one of the nicest guys in hollywood .\"]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"marseille , france - cnn - the french prosecutor leading an investigation into the crash of germanwings flight 9525 insisted wednesday that he was not aware of any video footage from on board the plane . marseille prosecutor brice robin told cnn that  so far no videos were used in the crash investigation . '' robin 's comments follow claims by two magazines , german daily bild and french paris match , of\",\n",
       " \"the formal accession was marked with a ceremony at the hague , in the netherlands , where the court is based . the palestinians signed the icc's founding rome statute in january . as members of the court , palestinians may be subject to counter-charges as well .\",\n",
       " \"amnesty international's annual report catalogs the use of state-sanctioned killing as a punitive measure across the globe . at least 607 people were executed around the world in 2014 . at least 2,466 people globally are confirmed to have been handed the sentence .\",\n",
       " 'amnesty international releases annual review of death penalty worldwide . death sentences up 500% on previous year, mostly because of pakistan . countries using death penalty to tackle crime and terrorism are deceiving themselves .',\n",
       " 'anne frank died of typhus in a nazi concentration camp at the age of 15 . new research shows that she and her older sister probably did not survive to march 1945 . the exact dates of death for anne and margot remain unclear .',\n",
       " \"a duke student has admitted to hanging a noose made of rope from a tree near a student union , university officials said thursday . the prestigious private school did n't identify the student , citing federal privacy laws . in a news release , it said the student was no longer on campus and will face student conduct review .\",\n",
       " \"the rev. robert h. schuller , california televangelist and founder of the television ministry  hour of power , '' died thursday , according to his family . he was 88 years old . schuller , also the founder of crystal cathedral megachurch , had been diagnosed with esophageal cancer in august 2013 .\",\n",
       " 'the dog was hit by a car, apparently killed with a hammer and buried in a field . she staggered to a nearby farm, dirt-covered and emaciated . the dog was found by a worker who took her to a vet for help . she suffered a dislocated jaw, leg injuries and a caved-in sinus cavity .',\n",
       " \"mohammad javad zarif is the iranian foreign minister . he has been john kerry's opposite number in securing nuclear breakthrough . zarif is 54, but his official biography says he was born in 1960 . he was investigated by the feds over his alleged role in controlling a charitable organization .\",\n",
       " \"for the first time in eight years , a tv legend returned to doing what he does best . contestants told to  come on down ! '' on the april 1 edition of  the price is right '' encountered not host drew carey but another familiar face in charge of the proceedings . instead , there was bob barker , who hosted the tv game show for 35 years before stepping down in 2007 .\",\n",
       " \"-lrb- he 's a blue chip college basketball recruit . she 's a high school freshman with down syndrome . at first glance trey moses and ellie meredith could n't be more different . but all that changed thursday when trey asked ellie to be his prom date .\",\n",
       " \"michele bachmann compared president obama to the co-pilot of the doomed germanwings flight . ''with his iran deal , barack obama is for the 300 million souls of the united states,'' she wrote in a facebook comment posted march 31 . many comments posted on her facebook page blasted the former representative .\",\n",
       " 'california is a breadbasket to the nation . california is growing more than a third of its vegetables and nearly two-thirds of its fruits and nuts . the drought is in its fourth year .',\n",
       " \"walmart's staunch criticism of a religious freedom law in its home state of arkansas came after the company said in february it would boost pay for about 500,000 workers well above the federal minimum wage . the company is emerging as a bellwether for shifting public opinion on hot-button political issues that divide conservatives and liberals . former minnesota gov. tim pawlenty said walmart's actions  foreshadow where the republican party will need to move \",\n",
       " \"five americans who were monitored for three weeks at an omaha hospital have been released . one of the five had a heart-related issue on saturday and has been discharged but has n't left the area . they were exposed to ebola in sierra leone in march .\",\n",
       " \"andrew getty, 47, was found dead in his los angeles home . the coroner's preliminary assessment is there was no foul play involved in the death of getty . getty , grandson of oil tycoon j. paul getty , was found dead near a bathroom in his home .\",\n",
       " \"mike pence signed a religious freedom law last week that opens the door to discrimination against gays and lesbians . pence: 'i foolishly hoped this kind of backlash . ''there is no way a republican can get through the pending primary without denouncing lgbt rights,'' he says .\",\n",
       " \"filipinos are being warned to be on guard for flash floods and landslides as tropical storm maysak approached the asian island nation saturday . just a few days ago , maysak gained super typhoon status thanks to its sustained 150 mph winds . it has since lost a lot of steam as it has spun west in the pacific ocean . it 's now classified as a tropical storm , according to the philippine national weather\",\n",
       " \"norfolk , virginia - the second mate of the houston express probably could n't believe what he was seeing . hundreds of miles from land there was a small boat nearby . at first it looked abandoned . it was in bad shape , listing to one side . the crew of the 1,000-foot long container ship thought it was a yacht that had wrecked . incredibly , as they got closer , they saw there was a man on it \",\n",
       " \"walker died in november 2013 after a fiery car crash . the release of  furious 7 '' on friday offers fans the opportunity to remember -- and possibly grieve again -- the man that so many have praised as one of the nicest guys in hollywood .\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['marseille , france - cnn - the french prosecutor leading',\n",
       " 'the formal accession was marked with a ceremony at the hague , in the net',\n",
       " \"amnesty international's annual report catalogs the use of state-sanction\",\n",
       " 'amnesty international releases annual review of death penalty worldwide . death sentences up 500%',\n",
       " 'anne frank died of typhus in a nazi concentration camp at the',\n",
       " 'a duke student has admitted to hanging a noose made of rope from',\n",
       " 'the rev. robert h. schuller , californ',\n",
       " 'the dog was hit by a car, apparently killed with a hammer and ',\n",
       " 'mohammad javad zarif is the iranian foreign minister ',\n",
       " 'for the first time in eight years , a tv legend returned to doing what',\n",
       " \"-lrb- he 's a blue chip college basketball recruit \",\n",
       " 'michele bachmann compared president obama to the co-pilot of',\n",
       " 'california is a breadbasket to the nation . cali',\n",
       " \"walmart's staunch criticism of a religious freedom law in its home state of ark\",\n",
       " 'five americans who were monitored for three weeks at an omaha hospital have been',\n",
       " 'andrew getty, 47, was found dead in his los angeles home',\n",
       " 'mike pence signed a religious freedom law last week that opens the door to discrimin',\n",
       " 'filipinos are being warned to be on guard for flash floods and landsl',\n",
       " 'norfolk , virginia - the second mate of the ',\n",
       " 'walker died in november 2013 after a fiery car crash . the release']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bild and paris match claim to have found a video of the crash site .',\n",
       " 'palestinian authority officially became the 123rd member of the international criminal court on we',\n",
       " \"amnesty international's annual report catalogs the use of state-sanction\",\n",
       " '. in egypt and nigeria , courts imposed',\n",
       " 'anne frank died of typhus in a nazi concentration camp at the',\n",
       " 'student admitted to hanging the noose from a tree near a student union ',\n",
       " \". schuller 's legacy is a televangelist \",\n",
       " '. a dog in california , found seemingly dead after',\n",
       " 'zarif is the iranian foreign minister . he has been ',\n",
       " \", he didn't seem to miss a beat . bob bark\",\n",
       " '. . . . . . . . .',\n",
       " 'michele bachmann compared president obama to the co-pilot of',\n",
       " '. . . . . . . . .',\n",
       " \"''  the republican party will have to better stand for '' ideas\",\n",
       " 'of an infected person . the last of 17 patients who were being monitored are',\n",
       " 'found dead in his home . he was found on his side near a bathroom',\n",
       " '. . . . . . . . ',\n",
       " \". ''we do not know what the impact will be once it will make\",\n",
       " '. he was rescued . he spent most of his days in the',\n",
       " \"walker 's death .walker 's death is not the first actor\"]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['marseille , france - cnn - the french prosecutor leading',\n",
       " 'the formal accession was marked with a ceremony at the hague , in the net',\n",
       " \"amnesty international's annual report catalogs the use of state-sanction\",\n",
       " 'amnesty international releases annual review of death penalty worldwide . death sentences up 500%',\n",
       " 'anne frank died of typhus in a nazi concentration camp at the',\n",
       " 'a duke student has admitted to hanging a noose made of rope from',\n",
       " 'the rev. robert h. schuller , californ',\n",
       " 'the dog was hit by a car, apparently killed with a hammer and ',\n",
       " 'mohammad javad zarif is the iranian foreign minister ',\n",
       " 'for the first time in eight years , a tv legend returned to doing what',\n",
       " \"-lrb- he 's a blue chip college basketball recruit \",\n",
       " 'michele bachmann compared president obama to the co-pilot of',\n",
       " 'california is a breadbasket to the nation . cali',\n",
       " \"walmart's staunch criticism of a religious freedom law in its home state of ark\",\n",
       " 'five americans who were monitored for three weeks at an omaha hospital have been',\n",
       " 'andrew getty, 47, was found dead in his los angeles home',\n",
       " 'mike pence signed a religious freedom law last week that opens the door to discrimin',\n",
       " 'filipinos are being warned to be on guard for flash floods and landsl',\n",
       " 'norfolk , virginia - the second mate of the ',\n",
       " 'walker died in november 2013 after a fiery car crash . the release']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 20\n",
      "Number of references: 1000\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2730cb016bfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrouge_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_rouge_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrouge_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dadendev/nlp-recipes/utils_nlp/eval/rouge/compute_rouge.py\u001b[0m in \u001b[0;36mcompute_rouge_python\u001b[0;34m(cand, ref, is_input_files, language)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of candidates: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of references: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlanguage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"en\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rouge_scores = compute_rouge_python(cand=prediction, ref=target)\n",
    "pprint.pprint(rouge_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing\n",
    "sb.glue(\"rouge_2_f_score\", rouge_scores['rouge-2']['f'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on a single input sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"\"\"\n",
    "But under the new rule, set to be announced in the next 48 hours, Border Patrol agents would immediately return anyone to Mexico â€” without any detainment and without any due process â€” who attempts to cross the southwestern border between the legal ports of entry. The person would not be held for any length of time in an American facility.\n",
    "\n",
    "Although they advised that details could change before the announcement, administration officials said the measure was needed to avert what they fear could be a systemwide outbreak of the coronavirus inside detention facilities along the border. Such an outbreak could spread quickly through the immigrant population and could infect large numbers of Border Patrol agents, leaving the southwestern border defenses weakened, the officials argued.\n",
    "The Trump administration plans to immediately turn back all asylum seekers and other foreigners attempting to enter the United States from Mexico illegally, saying the nation cannot risk allowing the coronavirus to spread through detention facilities and Border Patrol agents, four administration officials said.\n",
    "The administration officials said the ports of entry would remain open to American citizens, green-card holders and foreigners with proper documentation. Some foreigners would be blocked, including Europeans currently subject to earlier travel restrictions imposed by the administration. The points of entry will also be open to commercial traffic.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SummarizationDataset(\n",
    "    None,\n",
    "    source=[source],\n",
    "    source_preprocessing=[tokenize.sent_tokenize],\n",
    "    word_tokenize=nltk.word_tokenize,\n",
    ")\n",
    "processor = ExtSumProcessor(model_name=MODEL_NAME,  cache_dir=CACHE_DIR)\n",
    "preprocessed_dataset = processor.preprocess(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = summarizer.predict(preprocessed_dataset, num_gpus=0, batch_size=1, sentence_separator=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up temporary folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(DATA_PATH):\n",
    "    shutil.rmtree(DATA_PATH, ignore_errors=True)\n",
    "if os.path.exists(CACHE_DIR):\n",
    "    shutil.rmtree(CACHE_DIR, ignore_errors=True)\n",
    "if USE_PREPROCSSED_DATA:\n",
    "    if os.path.exists(PROCESSED_DATA_PATH):\n",
    "        shutil.rmtree(PROCESSED_DATA_PATH, ignore_errors=True)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python (nlp_gpu)",
   "language": "python",
   "name": "nlp_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
